* Node.js Topics :
1. Node.js Intro
2. Node.js Architecture
3. Node.js Modules
4. package.json & NPM
5. Node.js File System Module
6. Streams
7. Buffers
8. Http Module & Server
9. Node.js Internal Working



1. Node.js Intro :
Node.js is an open-source, cross-platform runtime environment that allows developers to execute JavaScript code on the server side.
It was created by Ryan Dahl in 2009.

Node.js is built on the V8 JavaScript engine, the same engine that powers Google Chrome. This engine compiles JavaScript into native machine code, which makes Node.js applications fast and efficient. The non-blocking, event-driven architecture of 
Node.js makes it particularly suitable for I/O-intensive operations, such as real-time applications, streaming services, and APIs.

node -v : display the installed version of Node.js.


2. Node.js Architecture :
Single-threaded, Event-driven, Non-blocking I/O Model.

A. Single-threaded : 
Unlike traditional server architectures that often use multiple threads to handle concurrent requests, Node.js operates on a single thread. This might seem limiting, but it’s actually a strength when combined with its event-driven model. The single-threaded nature simplifies programming and reduces overhead associated with context switching between threads.

B. Event-driven : 
Node.js operates on an event loop, which is a programming construct that waits for and dispatches events or messages in a program. This event loop continuously checks for events, such as I/O operations or network requests, and dispatches them to the appropriate handlers. When an event occurs, a callback function is executed. This allows Node.js to handle many concurrent operations efficiently.

C. Non-blocking I/O : 
Node.js uses non-blocking I/O operations, meaning it doesn't wait for an operation (like reading a file or making an HTTP request) to complete before moving on to the next task. Instead, it initiates the operation and moves on, handling the result once it's available through the event loop. This makes Node.js highly efficient for 
I/O-bound tasks, allowing it to handle thousands of concurrent connections with minimal overhead.

How It Works :
When a client sends a request to a Node.js server, the server processes the request without blocking the execution of other tasks.
If the request involves an I/O operation, such as reading from a file or querying a database, Node.js initiates the operation and immediately continues with the next task.
Once the I/O operation completes, the callback function is added to the event loop, and Node.js processes it when the thread is free.


3. Node.js Modules :
A module in Node.js is a reusable block of code whose existence does not impact other code unless explicitly imported. 

Node.js uses the CommonJS module system : require, module.exports 
Convert it into ES6 Module in package.json : "type": "module",
ES6 Modules : import, export

* Core Modules :
Node.js comes with several built-in modules that provide essential functionalities :

A. fs (File System) : 
Used to interact with the file system. It allows you to read, write, delete, and perform other operations on files and directories.
Example> 
const fs = require('fs');
fs.readFile('example.txt', 'utf8', (err, data) => {
  if (err) throw err;
  console.log(data);
});

B. http : 
Used to create HTTP servers and handle HTTP requests and responses.
Example>
const http = require('http');
const server = http.createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end('Hello, World!\n');
});
server.listen(3000, () => {
  console.log('Server running at http://localhost:3000/');
});

C. path : 
Provides utilities for working with file and directory paths.
Example>
const path = require('path');
const filePath = path.join(__dirname, 'example.txt');
console.log(filePath);

D. os : 
Provides operating system-related utility methods and properties, such as getting the system’s CPU architecture or uptime.
Example>
const os = require('os');
console.log(os.platform());
console.log(os.cpus());

E. url : 
Used to parse and format URLs.
const url = require('url');
const parsedUrl = url.parse('https://example.com/path?name=abc');
console.log(parsedUrl.hostname); // 'example.com'

* Custom Modules :
You can create your own custom modules in Node.js.
A. Create a new file, e.g., math.js.
and Define your module's functionality :
Example>
function add(a, b) {
  return a + b;
}
function subtract(a, b) {
  return a - b;
}
module.exports = { add, subtract };

B. Importing and Using a Custom Module :
In another file, e.g., app.js, import and use the custom module.
Example>
const math = require('./math');
console.log(math.add(5, 3)); // 8
console.log(math.subtract(5, 3)); // 2


4. package.json & NPM :
* package.json :
package.json is a file at the root of a Node.js project that holds various metadata relevant to the project. This file is essential for managing dependencies and scripts and is used by npm to install, update, and manage packages.

Key properties of package.json :
A. name: The name of your project.

B. version: The current version of your project.

C. dependencies: An object listing the packages that your project depends on, along with their versions.

D. scripts: A set of commands that can be run using npm run, such as starting the server or running tests.

E. main: The entry point of your application, typically index.js or app.js.

Example>
{
  "name": "my-node-project",
  "version": "1.0.0",
  "description": "A simple Node.js project",
  "main": "index.js",
  "scripts": {
    "start": "node index.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "dependencies": {
    "express": "^4.17.1"
  },
  "author": "Your Name",
  "license": "ISC"
}

* Installing, Updating, and Managing Packages :
A. Installing a Package :
To install a package, use the npm install command followed by the package name. By default, this installs the package locally and adds it to package.json as a dependency.
npm install express

To install a package globally (available across all projects), use the -g flag:
npm install -g nodemon

B. Updating a Package :
To update a package to the latest version within the version range specified in package.json:
npm update express

To update a package to the latest version available, outside of the version range:
npm install express@latest

C. Managing Packages :
To uninstall a package:
npm uninstall express

To list all installed packages and their versions:
npm list

To list globally installed packages:
npm list -g --depth=0

* Creating and Publishing Your Own Package :
If you've developed a reusable module, you can publish it as an npm package so that others can use it.
A. Create a new directory and initialize a new Node.js project.
mkdir my-package
cd my-package
npm init
Fill out the details, and npm will create a package.json file.

B. Write Your Code:
Create your module and export the functionality you want to share.

C. Publish the Package :
First, make sure you're logged in to npm:
npm login

Publish the package to the npm registry:
npm publish

Now, anyone can install your package using:
npm install your-package-name


5. Node.js File System Module :
The File System (fs) module in Node.js provides an API for interacting with the file system. It allows you to work with files and directories, enabling you to perform operations such as reading, writing, and deleting files, as well as creating and managing directories.

A. Reading Files :
* Asynchronous Reading: This method is preferred because it doesn’t block the execution of other code while reading the file.
Example>
const fs = require('fs');
fs.readFile('example.txt', 'utf8', (err, data) => {
  if (err) throw err;
  console.log(data);
});
In the above code:
fs.readFile is used to read the contents of example.txt.
The utf8 argument specifies the encoding.
The callback function is executed after the file is read, with err indicating if an error occurred and data containing the file contents.

* Synchronous Reading: This method blocks further code execution until the file is completely read.
Example>
const fs = require('fs');
const data = fs.readFileSync('example.txt', 'utf8');
console.log(data);
Use synchronous methods (readFileSync) when you need to ensure that the file is completely read before proceeding, but be aware that this can slow down your application if used improperly.

B. Writing Files :
* Asynchronous Writing :
Example>
const fs = require('fs');
const data = 'This is some new content';
fs.writeFile('example.txt', data, 'utf8', (err) => {
  if (err) throw err;
  console.log('File has been saved!');
});
fs.writeFile writes the content to example.txt.
If the file doesn’t exist, it’s created.
If it does exist, the content is overwritten.

* Synchronous Writing :
Example>
const fs = require('fs');
const data = 'This is some new content';
fs.writeFileSync('example.txt', data, 'utf8');
console.log('File has been saved!');

C.  Deleting Files :
* Asynchronous Deletion :
Example>
const fs = require('fs');
fs.unlink('example.txt', (err) => {
  if (err) throw err;
  console.log('File deleted!');
});
fs.unlink deletes the specified file. If the file doesn’t exist, an error is thrown.

* Synchronous Deletion :
const fs = require('fs');
fs.unlinkSync('example.txt');
console.log('File deleted!');

D. Working with Directories :
The fs module also provides methods to create, read, and delete directories.
create : fs.mkdir, fs.mkdirSync
read : fs.readdir, fs.readdirSync
delete : fs.rmdir, fs.rmdirSync 


6. Streams :
Streams are a powerful concept in Node.js, allowing you to handle data that is too large to fit into memory or needs to be processed in chunks. Streams are objects that let you read data from a source or write data to a destination continuously. There are four types of streams in Node.js:

A. Readable Streams: Streams from which data can be read, e.g., fs.createReadStream.

B. Writable Streams: Streams to which data can be written, e.g., fs.createWriteStream.

C. Duplex Streams: Streams that are both readable and writable, e.g., a TCP socket.

D. Transform Streams: Duplex streams where the output is computed based on the input, e.g., zlib compression.

* Example : Reading from a Stream>
const fs = require('fs');
const readableStream = fs.createReadStream('example.txt', 'utf8');
readableStream.on('data', (chunk) => {
  console.log(chunk);
});
fs.createReadStream reads the file in chunks instead of loading the entire file into memory.
The 'data' event is emitted every time a chunk of data is available, and the chunk is processed.

* Example : Writing to a Stream>
const fs = require('fs');
const writableStream = fs.createWriteStream('output.txt');
writableStream.write('Hello, World!\n');
writableStream.end('Goodbye, World!\n');
fs.createWriteStream creates a writable stream to output.txt.
Data is written to the file using the write method. The end method indicates that no more data will be written.

* Piping Streams :
Piping is a mechanism to connect a readable stream to a writable stream, allowing data to flow from the source directly to the destination.
Example>
const fs = require('fs');
const readableStream = fs.createReadStream('example.txt');
const writableStream = fs.createWriteStream('output.txt');
readableStream.pipe(writableStream);
In this example, the data from example.txt is read and directly written to output.txt using the pipe method.


7. Buffers :
Buffers are temporary storage areas for data that is being transferred between two locations. In Node.js, a buffer is a raw binary data storage similar to an array of integers but without a specific encoding. Buffers are typically used when dealing with binary data, such as reading from or writing to files or working with TCP streams.
Example> 
const buffer = Buffer.alloc(10);
console.log(buffer);
Buffer.alloc(size) creates a buffer of the specified size (in bytes). The buffer is initialized to zeros.

Example>
const buffer = Buffer.from('Hello, World!');
console.log(buffer);
Buffer.from(string) creates a buffer from the given string. The string is encoded as UTF-8 by default.

Example : Writing to a Buffer>
const buffer = Buffer.alloc(10);
buffer.write('Hello');
console.log(buffer.toString('utf8'));

Example : Reading from a Buffer>
const buffer = Buffer.from('Hello, World!');
console.log(buffer.toString('utf8'));

* Buffers are useful when you need to handle raw binary data, manipulate data at a byte level, or work with streams where data arrives in chunks and needs to be processed incrementally.


8. HTTP Module & Server :
Node.js includes a built-in module called http that allows you to create web servers and handle HTTP requests and responses.

Example>
const http = require('http');

const server = http.createServer((req, res) => {

  if (req.method === 'GET' && req.url === '/') {
    res.statusCode = 200;
    res.setHeader('Content-Type', 'text/plain');
    res.end('Home Page');
  } 
  else if (req.method === 'GET' && req.url === '/about') {
    res.statusCode = 200;
    res.setHeader('Content-Type', 'text/plain');
    res.end('About Page');
  } 
  else if (req.method === 'POST' && req.url === '/submit') {
    let body = '';
    req.on('data', (chunk) => {
      body += chunk.toString();
    });
    req.on('end', () => {
      res.statusCode = 200;
      res.setHeader('Content-Type', 'text/plain');
      res.end(`Data received: ${body}`);
    });
  } else {
    res.statusCode = 404;
    res.setHeader('Content-Type', 'text/plain');
    res.end('Not Found');
  }
});

const port = 3000;
server.listen(port, () => {
  console.log(`Server running at http://localhost:${port}/`);
});

In the above code :

http.createServer: Creates an HTTP server that listens for requests. The callback function (req, res) is executed every time a request is received.

req: Represents the incoming request and contains information about the request, such as the URL and HTTP method.

res: Represents the outgoing response. It is used to send data back to the client.

res.statusCode: Sets the HTTP status code for the response. In this case, 200 means "OK."

res.setHeader: Sets the HTTP headers for the response. The Content-Type header specifies the type of content being sent.

res.end: Ends the response and sends it to the client.

* HTTP Methods : GET, POST, PATCH, PUT, DELETE

req.on('data'): Listens for data events, which contain chunks of data sent in the POST request. These chunks are combined into the body variable.

req.on('end'): Signals the end of the data stream. At this point, the server can process the complete data.

*  const mimeTypes = {
      '.html': 'text/html',
      '.js': 'text/javascript',
      '.css': 'text/css',
      '.json': 'application/json',
      '.png': 'image/png',
      '.jpg': 'image/jpg',
      '.gif': 'image/gif',
      '.wav': 'audio/wav',
      '.mp4': 'video/mp4',
      '.woff': 'application/font-woff',
      '.ttf': 'application/font-ttf',
      '.eot': 'application/vnd.ms-fontobject',
      '.otf': 'application/font-otf',
      '.svg': 'application/image/svg+xml',
    };

//In express, Serve static files from the "public" directory
app.use(express.static(path.join(__dirname, 'public')));


9. Node.js Internal Working :
To understand how Node.js works internally, it’s important to break down its architecture and key components, including the V8 Engine, Event Loop, Libuv, Thread Pool, C++ bindings, and Core Modules. These components work together to enable 
Node.js to efficiently handle I/O operations and execute JavaScript code in a non-blocking, event-driven manner.

1. V8 Engine :
Role: 
The V8 Engine is the JavaScript engine developed by Google, which powers Node.js. It’s written in C++ and is responsible for compiling JavaScript into machine code that can be executed by the computer’s CPU.

How It Works:
When you write JavaScript code in Node.js, the V8 engine compiles this code into highly optimized machine code.
V8 uses just-in-time (JIT) compilation, meaning it compiles code at runtime, allowing for optimizations based on how the code is executed.

2. Event Loop :
Role: 
The event loop is the core of Node.js's asynchronous, non-blocking architecture. It continuously checks for events and executes the corresponding callback functions.

How It Works :
When Node.js starts, it initializes the event loop and begins executing the code.
Synchronous code is executed first, after which the event loop starts processing asynchronous events.
The event loop cycles through different phases: timers, pending callbacks, 
idle/preparation, poll, check, and close callbacks.
Each phase has a specific purpose, such as executing callbacks for timers, handling pending I/O callbacks, or checking for additional operations before the loop completes.

* Event Loop Phases :
A. Timers Phase: Handles the execution of callbacks scheduled by setTimeout() and setInterval().

B. Pending Callbacks Phase: Executes callbacks for some system operations, like errors from network operations.

C. Idle, Prepare Phase: Only used internally by Node.js for special purposes, often related to performance tuning.

D. Poll Phase: The most crucial phase, where the event loop retrieves new I/O events, executes I/O callbacks, and if the script is idle, waits for new events.

E. Check Phase: Executes setImmediate() callbacks.
Close Callbacks Phase: Handles the closing of connections, like socket.on('close', ...) callbacks.

3. Libuv :
Role: Libuv is a multi-platform C library that provides Node.js with asynchronous I/O capabilities, event loop management, and a thread pool. It’s one of the key components that allow Node.js to be non-blocking.

How It Works :
A. Cross-platform Abstraction: Libuv abstracts away the platform-specific details of I/O operations, enabling Node.js to run on multiple operating systems (Windows, macOS, Linux, etc.).

B. Thread Pool: For I/O operations that are not inherently non-blocking (e.g., file system operations), Libuv uses a thread pool. This allows these operations to be performed off the main thread, ensuring they don't block the event loop.

C. Event Loop Implementation: Libuv implements the event loop that Node.js uses. The event loop is divided into different phases, as discussed above.

4. Thread Pool :
Role: 
The thread pool in Node.js (managed by Libuv) is used to handle operations that cannot be performed asynchronously at the system level.

How It Works :
Default Size: The default size of the thread pool is 4 threads, but it can be configured using the UV_THREADPOOL_SIZE environment variable.
Tasks in the Pool: Tasks such as file system I/O, DNS resolution, compression, and some cryptographic operations are offloaded to the thread pool. Each task is assigned to a thread in the pool, allowing these operations to run in parallel without blocking the event loop.
Task Completion: Once a task in the thread pool is completed, its callback is queued in the event loop, which will eventually process it.

5. C++ Bindings :
Role: Node.js includes C++ bindings that expose low-level system functionalities to JavaScript through the V8 engine. These bindings are crucial for performance-intensive operations and for accessing system resources not directly available in JavaScript.
How It Works:
Native Modules: Some Node.js core modules are implemented in C++ (e.g., the fs module for file system operations) to maximize performance.
Binding Mechanism: These C++ modules are bound to JavaScript functions, allowing developers to call them as if they were regular JavaScript functions, while actually invoking highly optimized C++ code under the hood.

6. Core Modules :
Role: 
Core modules are the built-in modules that come with Node.js, providing essential functionalities like file system access, networking, and HTTP handling.

How It Works :
A. Pre-compiled: These modules are pre-compiled into the Node.js binary, so they load very quickly compared to user-installed modules.

B. JavaScript & C++: Some core modules are purely JavaScript, while others are a mix of JavaScript and C++ for performance reasons.

Examples: Common core modules include fs (file system operations), http (HTTP server and client functionality), path (file and directory paths), and crypto (cryptographic operations).

*  Node.js Execution Flow :
A. Initialization:
When a Node.js application starts, it initializes the V8 engine, sets up the event loop, and loads the core modules.

B. Code Execution:
Node.js begins executing the top-level code (i.e., the main script). If there are any asynchronous operations (e.g., file reads, HTTP requests), they are offloaded, and the callbacks are registered with the event loop.

C. Event Loop Operation:
The event loop enters its phases, checking for expired timers, processing I/O callbacks, and executing any pending tasks. If the event loop finds new events (e.g., a completed I/O operation), it invokes the corresponding callback functions.

D. Non-blocking Operations:
For I/O operations, Node.js uses the non-blocking capabilities provided by Libuv. Tasks that require blocking operations are executed in the thread pool, allowing the event loop to remain unblocked.

E. Event Handling:
The event loop continues to process events until there are no more pending operations, at which point the application exits.


** How Node.js internally executed Synchronous vs Asynchronous tasks :

* Synchronous Tasks :
Synchronous tasks in Node.js are executed in a blocking manner, which means each task is executed one after another. The current task must be completed before the next one is started. If a task takes a long time to complete (e.g., a CPU-intensive task), it will block the execution of other tasks.

Execution Flow:
The JavaScript engine (V8) reads the code line by line.
Each synchronous task is executed in the main thread (the event loop's call stack).
The result is returned immediately, and control moves to the next task.
If a task takes a long time, it blocks the subsequent tasks from being executed until it's done.

* Asynchronous Tasks :
Asynchronous tasks are handled differently in Node.js. Instead of waiting for a task to complete, Node.js delegates it to the event loop and allows the execution of other tasks while waiting for the result.

Asynchronous tasks typically involve I/O operations such as reading files, making network requests, or accessing databases. These operations are handed off to libuv, which manages the underlying system's asynchronous APIs. Once the operation is complete, the callback or promise is triggered, and the event loop returns to handle the result.

Execution Flow:
Asynchronous tasks are offloaded to the event loop.
The main thread doesn't wait for the task to finish and moves on to execute the next task.
When the asynchronous task completes, the event loop handles the callback or resolves the promise.
This allows Node.js to handle multiple tasks efficiently without blocking the main thread.

* Node.js Execution Architecture :
Node.js uses the event loop along with libuv to manage asynchronous tasks. Here’s a detailed explanation of the process:

a. Call Stack :
This is where synchronous code is executed in a Last-In-First-Out (LIFO) manner.
Each function call is pushed onto the call stack. Once executed, it’s popped off the stack.

b. Node.js Event Loop :
The event loop is at the heart of asynchronous execution. It continuously checks the call stack and event queues to determine what to execute next.
When an asynchronous task (like a network request) is initiated, Node.js hands it over to libuv, which interacts with the OS’s I/O mechanism.
While waiting for the I/O operation to complete, the event loop continues executing other tasks in the call stack.
Once the asynchronous task is complete, the event loop picks up the callback from the task queue and pushes it to the call stack for execution.

c. Libuv and Thread Pool :
libuv manages all the non-blocking, asynchronous I/O operations (file system, network requests, etc.). It uses the underlying operating system’s asynchronous mechanisms where possible.
For certain I/O operations like file system access, Node.js uses a thread pool (default size: 4 threads). This thread pool allows multiple operations to run concurrently, without blocking the main event loop.

* Example> Synchronous tasks are handled in the main thread via the call stack.
Asynchronous tasks are offloaded to the event loop and handled when they complete, without blocking the main thread.

console.log("Start"); // Synchronous

setTimeout(() => {
  console.log("Asynchronous Task"); // Asynchronous
}, 2000);

console.log("Synchronous Task"); // Synchronous

fetchData(() => {
  console.log("Asynchronous Fetch Complete"); // Asynchronous
});

console.log("End"); // Synchronous

Execution Breakdown:
"Start" is logged immediately (synchronous).
setTimeout is initiated but the callback is deferred (asynchronous).
"Synchronous Task" is logged immediately (synchronous).
An asynchronous task (fetchData) is initiated and deferred.
"End" is logged immediately (synchronous).
After 2 seconds, the setTimeout callback logs "Asynchronous Task."
Once fetchData completes, it logs "Asynchronous Fetch Complete."


                  ** End **
