MongoDB Topics :
1. MongoDB Intro
2. Document & Collection
3. SQL based DB (MySQL) vs NoSQL based DB (MongoDB)
4. Models, Schemas and Validation
5. MongoDB Methods for Express
6. MongoDB Querying and Operators
7. Aggregation Pipeline 
8. Relationships in MongoDB
9.
10. 




1. MongoDB Intro :
MongoDB is a popular NoSQL database that stores data in a flexible, JSON-like format called BSON (Binary JSON). Unlike traditional SQL databases that use tables and rows, MongoDB uses collections and documents, which allows for more flexible data structures and easier scalability. It is well-suited for applications that require large-scale data storage, high performance, and horizontal scaling.

Overview of MongoDB and Its Architecture :
MongoDB's architecture is designed to provide high availability, scalability, and flexibility:

A. Documents and Collections (Below in Topic 2 in details)

B. Replica Sets :
A replica set is a group of MongoDB servers that maintain the same data, providing redundancy and high availability. In a replica set, one node is the primary node that handles all write operations, and the others are secondary nodes that replicate the primary node's data.

C. Sharding :
Sharding is the process of distributing data across multiple servers, known as shards, to horizontally scale the database. Each shard stores a subset of the data, and MongoDB automatically balances the data across the shards.

D. Indexing :
MongoDB supports indexing to improve the performance of queries. Indexes can be created on one or more fields in a document, similar to indexes in SQL databases.

* Setup :
After MongoDB installation, you can start the MongoDB server using the mongod command.
The MongoDB server listens on port 27017 by default.
You can interact with MongoDB using the mongo shell, which provides a command-line interface for running queries and managing the database.
Optionally, you can use a GUI tool like MongoDB Compass or a web-based tool like MongoDB Atlas to manage your databases and collections visually.

* Why MongoDB Commonly used with MERN :

A. JavaScript and JSON Compatibility :
Data Format: MongoDB uses a JSON-like format (BSON) for data storage, which aligns well with JavaScript and JSON used in Express.js applications. This makes it easier to work with data in a format that is naturally compatible with JavaScript objects.
Seamless Integration: MongoDB integrates smoothly with JavaScript-based stacks (like MEAN/MERN) due to this compatibility.

B. Schema Flexibility :
Dynamic Schema: MongoDB allows for a flexible schema where documents can have different structures within the same collection. This flexibility is useful for applications with evolving data models or diverse data types.
Rapid Development: This schema-less nature supports rapid development and iteration, which is advantageous for agile development practices.

C. Scalability :
Horizontal Scaling: MongoDB supports horizontal scaling through sharding, which helps distribute data across multiple servers. This is beneficial for handling large-scale applications and high traffic loads.
Performance: The ability to scale out by adding more nodes helps maintain performance as the application grows.

D. Ease of Use with Node.js :
Native Driver: MongoDB provides a native Node.js driver, and libraries like Mongoose simplify data modeling and interactions, making it easy to work with MongoDB in an Express.js application.
Asynchronous Operations: MongoDB’s asynchronous operations fit well with Node.js’s non-blocking architecture, enhancing performance and responsiveness.


2. Document & Collection :
* Document :
A document in MongoDB is a basic unit of data, similar to a row in a relational database, but much more flexible. Documents are stored in a format called BSON (Binary JSON), which allows for storing data in a way that is both human-readable (when converted to JSON) and efficient for storage and retrieval.

Example>
{
  "_id": "5f8f8c44b54764421b7156c4",
  "name": "John Doe",
  "age": 30,
  "email": "john.doe@example.com",
  "address": {
    "street": "123 Main St",
    "city": "Anytown",
    "zip": "12345"
  },
  "hobbies": ["reading", "gaming", "hiking"]
}

* Key Characteristics of a Document :

A. Key-Value Pairs : 
A document is composed of key-value pairs. Each key is a string, and the value can be of various data types, including strings, numbers, arrays, objects, and more.
One key-value pair form a single field in the document.

B. Dynamic Schema : 
Unlike relational databases, where all rows must follow the same structure (i.e., the same columns), MongoDB documents within the same collection can have different structures. This is known as a dynamic schema or schema-less design.

C. Nested Documents : 
Documents can contain nested structures, including other documents and arrays. This allows for more complex data representations.

D. Unique Identifier (_id): 
Every document has a unique identifier stored in the _id field, which MongoDB uses to uniquely identify documents within a collection. The _id field is automatically generated if not provided.

Advantages of MongoDB Documents :
A. Flexibility: Documents can evolve over time, accommodating new fields as needed without altering the existing data structure.

B. Rich Data Representation: Documents can represent complex, hierarchical data with nested documents and arrays.

C. Easy Mapping: Documents map naturally to objects in programming languages, making MongoDB a good fit for modern application development.

* Collection :
A collection in MongoDB is a grouping of documents, similar to a table in a relational database. Collections do not enforce a schema, meaning the documents within a collection can have varying structures.

* Key Characteristics of a Collection :
A. Grouping of Documents: 
Collections are containers for documents. All documents within a collection are typically related by purpose or type, but they can have different fields and data types.
Example>
db.users.insertOne({
  "name": "John Doe",
  "email": "john.doe@example.com"
});

db.orders.insertOne({
  "userId": "5f8f8c44b54764421b7156c4",
  "items": ["item1", "item2"],
  "total": 100
});
Here, users and orders are two different collections containing documents relevant to their respective purposes.

B. No Enforced Schema: 
Collections do not enforce a strict schema. This means you can have documents with different structures within the same collection.
Example>
db.users.insertMany([
  { "name": "Alice", "age": 28 },
  { "name": "Bob", "email": "bob@example.com" }
]);
The users collection has documents with different fields (age and email).

C. High-Performance Operations: 
Collections are optimized for high performance and scalability. You can perform CRUD (Create, Read, Update, Delete) operations on collections efficiently, even as they grow to contain millions of documents.

D. Indexes: 
Collections can have indexes on specific fields to optimize query performance. For example, creating an index on the email field in a users collection would speed up searches for users by email.

E. Collection Naming: 
Collection names should be descriptive and typically lowercase. They cannot contain special characters like \0, and it's a good practice to use plural forms (e.g., users, orders).

* Collections in Express.js with Mongoose Example :
const mongoose = require('mongoose');

const userSchema = new mongoose.Schema({
  name: String,
  email: String,
  age: Number
});

const User = mongoose.model('User', userSchema);

// 'User' model corresponds to the 'users' collection in MongoDB


3. SQL based DB (MySQL) vs NoSQL based DB (MongoDB) :

A. Data Model :

A.1> SQL (MySQL):
Structured Data: SQL databases use a structured schema with tables and rows. Each table has a predefined schema with columns and data types.
Relationships: They support complex queries and relationships through JOIN operations between tables.

A.2> NoSQL (MongoDB):
Unstructured Data: NoSQL databases like MongoDB use a flexible, document-oriented data model. Data is stored in collections as JSON-like documents, which can have varying structures.
Relationships: They often use denormalization and embedding for handling relationships, which can simplify querying at the cost of potential redundancy.

B. Schema :

B.1> .SQL (MySQL):
Fixed Schema: SQL databases require a predefined schema that must be defined before data insertion. Changes to the schema typically involve migration scripts.

B.2> NoSQL (MongoDB):
Flexible Schema: NoSQL databases allow for dynamic schemas. Documents within the same collection can have different fields and structures.

C. Scalability :

C.1> SQL (MySQL):
Vertical Scaling: SQL databases generally scale vertically by upgrading server hardware (CPU, RAM). This can be more challenging and expensive as the database grows.

C.2> NoSQL (MongoDB):
Horizontal Scaling: NoSQL databases are designed for horizontal scaling, which involves distributing data across multiple servers or nodes. This approach helps handle large volumes of data and high traffic loads more efficiently.

D. Query Language :

D.1> SQL (MySQL):
SQL (Structured Query Language): Uses SQL for defining and manipulating data. SQL is a powerful and standardized language for querying relational databases.

D.2> NoSQL (MongoDB):
Query Language: MongoDB uses its own query language based on JavaScript syntax. It provides a rich set of querying capabilities but is different from SQL.

E. Transactions :

E.1> SQL (MySQL):
ACID Transactions: SQL databases typically support ACID (Atomicity, Consistency, Isolation, Durability) transactions, ensuring data integrity and reliability for complex transactions.

E.2> NoSQL (MongoDB) :
Limited Transactions: Historically, NoSQL databases had limited support for transactions. However, modern versions of MongoDB (4.x and later) support multi-document transactions with ACID properties.

F. Use Cases :

F.1> SQL (MySQL):
Complex Queries: Suitable for applications requiring complex queries and data relationships, such as financial systems, traditional business applications, and data warehouses.

F.2> NoSQL (MongoDB):
Flexible and Scalable: Ideal for applications with rapidly changing requirements, unstructured data, and those requiring high scalability and performance, such as content management systems, real-time analytics, and social networks.

* Static Schema vs Dynamic Schema :
* Static Schema in MySQL :
In MySQL, a static schema means that the structure of the database (i.e., tables, columns, data types) must be defined before inserting data. This schema is rigid and enforces consistency in the data.

Example>
step 1>
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    username VARCHAR(255) NOT NULL,
    email VARCHAR(255) NOT NULL,
    age INT
);

step 2>
INSERT INTO users (username, email, age) VALUES ('john_doe', 'john@example.com', 30);

step 3>
ALTER TABLE users ADD COLUMN address VARCHAR(255);

After this, you can start inserting data with the new address field. But before that, any existing data will not have this field, and if you don’t allow NULL values, you must provide a default value or populate this field.

* Dynamic Schema in MongoDB
In MongoDB, a dynamic schema means that documents in a collection can have different structures. You don't need to define a schema before inserting data, and each document can have different fields.

For the same application as above in MySQL, we can insert documents into a users collection without defining a schema:

You can insert data directly with any fields you like:
db.users.insertOne({
    username: "john_doe",
    email: "john@example.com",
    age: 30
});

Later, if you want to add an address field, you can do so without altering the schema:
db.users.insertOne({
    username: "jane_doe",
    email: "jane@example.com",
    age: 25,
    address: "123 Main St"
});

Mixed Documents in MongoDB:
MongoDB allows documents within the same collection to have different fields:
db.users.insertOne({
    username: "bob_smith",
    email: "bob@example.com"
});

In this case:
The first document has username, email, and age.
The second document has username, email, age, and address.
The third document has only username and email.


4. Models, Schemas and Validation :
Connect MongoDB with Express.js by : Mongoose or MongoDB Native Driver.
npm install mongoose
npm install mongodb

* Schema :
A schema in Mongoose is an object that defines the structure of a document within a MongoDB collection. It specifies the fields, data types, and any constraints or validations.

* Model :
A model in Mongoose is a wrapper for a schema, providing an interface for interacting with the corresponding MongoDB collection.

* Schema Types :
Mongoose supports a variety of schema types, each corresponding to a MongoDB data type:
String: Represents text data.
Number: Represents numeric data.
Date: Represents date and time.
Boolean: Represents true/false values.
Array: Represents an array of values (e.g., [String] for an array of strings).
ObjectId: Represents a reference to another document.
Mixed: A flexible type that can hold any data (used sparingly).

* Validations :
Mongoose allows you to add validations to your schema to enforce data integrity:
required: Ensures the field is not empty.
unique: Ensures the value is unique in the collection.
min and max: Set minimum and maximum values for numbers.
enum: Restricts the value to a specific set of values.
match: Validates the field value against a regular expression.

Example>
const productSchema = new mongoose.Schema({
  name: { type: String, required: true },
  price: { type: Number, required: true, min: 0 },
  category: { type: String, enum: ['Electronics', 'Clothing', 'Food'] },
  inStock: { type: Boolean, default: true },
  author: { type: mongoose.Schema.Types.ObjectId, ref: 'User' },
  tags: [String],
  username: {
    type: String,
    validate: {
      validator: function(v) {
        return /^[a-zA-Z0-9]+$/.test(v); // Alphanumeric only
      },
      message: props => `${props.value} is not a valid username!`
    },
    required: [true, 'User name required']
  }
});

* Instance Methods :
Instance methods are functions that can be called on individual document instances. You define them on the schema.
Example>
userSchema.methods.sayHello = function() {
  console.log(`Hello, my name is ${this.name}`);
};
const User = mongoose.model('User', userSchema);
const user = new User({ name: 'Alice' });
user.sayHello(); // Outputs: Hello, my name is Alice

* Static Methods :
Static methods are functions that can be called on the model itself, rather than on an instance of a document.
Example>
userSchema.statics.findByEmail = function(email) {
  return this.findOne({ email });
};
const User = mongoose.model('User', userSchema);
User.findByEmail('alice@example.com').then(user => {
  console.log(user);
});

* Virtuals :
Virtuals are properties that are not stored in MongoDB but are computed on the fly.
Example>
userSchema.virtual('fullName').get(function() {
  return `${this.firstName} ${this.lastName}`;
});
const User = mongoose.model('User', userSchema);
const user = new User({ firstName: 'Alice', lastName: 'Smith' });
console.log(user.fullName); // Outputs: Alice Smith

* Validation and Sanitization :

* Async Validation: 
Mongoose also supports asynchronous validation if you need to perform checks that involve querying the database.
Example>
userSchema.path('email').validate(async function (value) {
  const user = await User.findOne({ email: value });
  return !user; // Ensure email is not already taken
}, 'Email already in use');

* express-validator :
npm install express-validator
Example of using express-validator to validate and sanitize data in an Express route:

const { body, validationResult } = require('express-validator');
app.post('/register', [
  body('name').isString().notEmpty(),
  body('email').isEmail().normalizeEmail(),
  body('age').isInt({ min: 18, max: 120 })
], (req, res) => {
  const errors = validationResult(req);
  if (!errors.isEmpty()) {
    return res.status(400).json({ errors: errors.array() });
  }
  // Proceed with saving to the database
  // ...
});

* Sanitizing and Transforming Data Before Saving :
Sanitization and transformation involve cleaning and modifying data before it is saved to the database. This step ensures that data is not only valid but also in a format that is safe and consistent.

* Sanitization :
express-validator can also sanitize input data to prevent issues like SQL injection or XSS attacks.
Removing or escaping potentially harmful characters from user inputs.

Example> body('email').normalizeEmail();
The normalizeEmail() method will clean up the email address, ensuring it's in a consistent format.

Example>
const sanitizeHtml = require('sanitize-html');

userSchema.pre('save', function (next) {
  this.name = sanitizeHtml(this.name);
  next();
});
In this example, sanitizeHtml is used to clean the name field of any HTML or JavaScript code before saving it to the database.

* Transformation :
Modifying data to ensure it fits certain formats or standards.
Example>
userSchema.pre('save', function (next) {
  this.email = this.email.toLowerCase();
  next();
});
Here, the email field is transformed to lowercase before saving, ensuring consistent email format.


5. MongoDB Methods for Express :

A. save():
The save() method is used to save a new document to the database. You first create an instance of a Mongoose model and then call save() to store it.

B. create():
The create() method is a shorthand for creating and saving a document in one step. It directly takes an object with the document data and stores it in the database.

C. find():
The find() method is used to retrieve multiple documents from the database that match a given query. It returns an array of documents.

D. findOne():
The findOne() method is used to retrieve a single document that matches a given query. It returns the first matching document.

E. findById():
The findById() method is used to find a document by its unique _id field.

F. updateOne():
The updateOne() method updates a single document that matches a given query. It modifies the first matching document.

G. updateMany():
The updateMany() method updates multiple documents that match a given query.

H. findByIdAndUpdate():
The findByIdAndUpdate() method finds a document by its _id and updates it. It returns the updated document by default (you can change this behavior using options).

I. deleteOne():
The deleteOne() method deletes a single document that matches a given query.

J. deleteMany():
The deleteMany() method deletes multiple documents that match a given query.

K. findByIdAndDelete():
The findByIdAndDelete() method finds a document by its _id and deletes it.

Example>
User.find({ age: { $gte: 21 } }, (err, users) => {
  if (err) {
    console.error('Error finding users:', err);
  } else {
    console.log('Users found:', users);
  }
});


6. MongoDB Querying & Operators :
MongoDB provides powerful tools for querying and filtering data, enabling you to retrieve exactly what you need. This involves using conditions, operators, pagination, sorting, and more advanced techniques like aggregation pipelines.

Example> User.find({ age: 25, status: 'active' }, (err, users) => {
  if (err) {
    console.error('Error finding users:', err);
  } else {
    console.log('Active users aged 25:', users);
  }
});
This query finds users who are both 25 years old and have a status of "active."

* MongoDB Operators :
MongoDB provides various operators to perform more complex queries. Some commonly used operators include:

A. Comparison Operators :
1. $gt (greater than), $gte (greater than or equal to)
2. $lt (less than), $lte (less than or equal to)
3. $eq (equal), $ne (not equal)

Example>
User.find({ age: { $gte: 18, $lte: 30 } }, (err, users) => {
  if (err) {
    console.error('Error finding users:', err);
  } else {
    console.log('Users aged between 18 and 30:', users);
  }
});
This query finds users whose age is greater than or equal to 18 
and Less than or equal to 30.

B. Logical Operators :
$and: Combine multiple conditions (all must be true).
$or: Combine multiple conditions (at least one must be true).
$not: Invert the effect of a query.
$nor: Combine multiple conditions (none must be true).

Example> 
User.find({
  $or: [{ age: { $lt: 18 } }, { age: { $gt: 65 } }]
}, (err, users) => {
  if (err) {
    console.error('Error finding users:', err);
  } else {
    console.log('Users younger than 18 or older than 65:', users);
  }
});

C. Array Operators :
$in: Match any of the values specified in an array.
$nin: Match none of the values specified in an array.
$all: Match all elements specified in an array.

Example>
User.find({ status: { $in: ['active', 'pending'] } }, (err, users) => {
  if (err) {
    console.error('Error finding users:', err);
  } else {
    console.log('Active or pending users:', users);
  }
});

* Sorting Results :
You can sort query results using the sort() method.
Example>
User.find()
  .sort({ age: -1 }) // Sort by age in descending order
  .exec((err, users) => {
    if (err) {
      console.error('Error sorting users:', err);
    } else {
      console.log('Sorted users:', users);
    }
  });

* Pagination :
Pagination is typically done using skip() and limit() methods.
Example>
const page = 2;
const limit = 10;

User.find()
  .skip((page - 1) * limit) // Skip the previous page's results
  .limit(limit) // Limit the results to the current page size
  .exec((err, users) => {
    if (err) {
      console.error('Error paginating users:', err);
    } else {
      console.log('Paginated users:', users);
    }
  });


7. Aggregation Pipeline :
The MongoDB Aggregation Pipeline is a powerful framework for performing data processing and transformation on collections. It allows you to process documents in a collection by passing them through a series of stages, each stage transforming the documents in some way. This is particularly useful for generating reports, filtering data, and performing complex queries.

* Key Concepts of Aggregation Pipeline :
A. Stages: The pipeline consists of multiple stages, each stage performing an operation on the data. Common stages include $match, $group, $sort, $project, and more.

B. Pipeline: A sequence of stages that process documents. The output of one stage is passed as input to the next stage.

C. Operators: Each stage uses operators to define the transformation, filtering, or grouping criteria.

* Common Aggregation Pipeline Stages :

A. $match: Filters the documents to pass only those that match the specified 
condition(s).
Similar to the find() method, but used within the pipeline.
Example> { $match: { status: "active" } }

B. $group: Groups documents by a specified field and performs aggregations like sum, average, count, etc.
Example> {
  $group: {
    _id: "$category",
    totalSales: { $sum: "$amount" },
    averageSales: { $avg: "$amount" }
  }
}

C. $sort: Sorts the documents based on the specified field(s).
Example> { $sort: { totalSales: -1 } } // Sort by totalSales in descending order

D. $project: Reshapes each document by including, excluding, or adding new fields.
Example> { $project: { name: 1, totalSales: 1, salesCategory: "$category" } }

E. $limit: Limits the number of documents passed to the next stage.
Example> { $limit: 5 } // Limit the result to 5 documents

F. $skip: Skips a specified number of documents, useful for pagination.
Example> { $skip: 10 } // Skip the first 10 documents

G. $lookup: Performs a left outer join to another collection in the same database to filter in documents from the "joined" collection.
Example> {
  $lookup: {
    from: "orders",
    localField: "_id",
    foreignField: "customerId",
    as: "orders"
  }
}

H. $unwind: Deconstructs an array field from the input documents to output a document for each element of the array.
Example> { $unwind: "$items" }

I. $cond: Use $cond within a stage to apply conditional logic.
Example> {
  $project: {
    discountApplied: {
      $cond: { if: { $gte: ["$amount", 100] }, then: true, else: false }
    }
  }
}

* Performance Considerations :
A. Indexing: Ensure that fields used in $match, $group, and $sort stages are indexed to improve performance.

B. Pipeline Optimization: Place $match and $limit stages as early as possible in the pipeline to reduce the number of documents processed by subsequent stages.

C. Avoid Large $group Results: Grouping can be memory-intensive, so try to minimize the number of documents in the $group stage by filtering early.

* Example: Aggregation Pipeline in an Express.js Application :
Let's say we have a MongoDB collection called orders containing documents that represent orders placed by customers. We want to build an aggregation pipeline that:

Filters orders by status.
Groups orders by customer and calculates the total amount spent by each customer.
Sorts the customers by their total spending in descending order.
Limits the result to the top 10 customers.
Here's how you could implement this in an Express.js route:

Example>
const express = require('express');
const mongoose = require('mongoose');
const app = express();

// Assuming you have an Order model
const Order = mongoose.model('Order', new mongoose.Schema({
  customerId: mongoose.Schema.Types.ObjectId,
  amount: Number,
  status: String,
}));

app.get('/top-customers', async (req, res) => {
  try {
    const pipeline = [
      { $match: { status: 'completed' } },  // Stage 1: Filter orders by status
      { 
        $group: {  // Stage 2: Group by customerId and calculate total spending
          _id: "$customerId",
          totalSpent: { $sum: "$amount" }
        }
      },
      { $sort: { totalSpent: -1 } },  // Stage 3: Sort by totalSpent in descending order
      { $limit: 10 }  // Stage 4: Limit to top 10 customers
    ];

    const topCustomers = await Order.aggregate(pipeline).exec();
    res.json(topCustomers);
  } catch (err) {
    res.status(500).json({ error: err.message });
  }
});

mongoose.connect('mongodb://localhost:27017/yourdbname', { useNewUrlParser: true, useUnifiedTopology: true })
  .then(() => app.listen(3000, () => console.log('Server running on port 3000')))
  .catch(err => console.error(err));


8. Relationships in MongoDB :
MongoDB is a NoSQL database that does not enforce relationships between documents like traditional SQL databases. However, you can still model relationships between documents using two main techniques: embedding documents and referencing documents.

A. One-to-Many Relationships :
In a one-to-many relationship, a single document in one collection is related to multiple documents in another collection. For example, a User might have multiple Posts.

* Example 1 : Using References>

User Schema:
const userSchema = new mongoose.Schema({
  name: String,
  email: String
});

Post Schema:
const postSchema = new mongoose.Schema({
  title: String,
  content: String,
  author: { type: mongoose.Schema.Types.ObjectId, ref: 'User' }
});
Here, the Post schema has an author field that references the User schema.

Query Example:
Post.find({ author: userId }).exec((err, posts) => {
  if (err) {
    console.error('Error finding posts:', err);
  } else {
    console.log('Posts by user:', posts);
  }
});

* Example 2 : Using Embedding>
User Schema with Embedded Posts:
const userSchema = new mongoose.Schema({
  name: String,
  email: String,
  posts: [{ title: String, content: String }]
});
This approach embeds posts directly within the User document. It is useful when the relationship data is closely tied and frequently accessed together.

B. Many-to-Many Relationships :
In a many-to-many relationship, multiple documents in one collection are related to multiple documents in another collection. For example, Students and Courses where students can enroll in multiple courses and courses can have multiple students.

* Example 1 : Using References>

Student Schema:
const studentSchema = new mongoose.Schema({
  name: String,
  courses: [{ type: mongoose.Schema.Types.ObjectId, ref: 'Course' }]
});

Course Schema:
const courseSchema = new mongoose.Schema({
  title: String,
  students: [{ type: mongoose.Schema.Types.ObjectId, ref: 'Student' }]
});

Adding a Student to a Course:
Course.findByIdAndUpdate(courseId, { $push: { students: studentId } }, (err, course) => {
  if (err) {
    console.error('Error updating course:', err);
  } else {
    console.log('Student added to course:', course);
  }
});

* Example 2 : Using Embedding>

Student Schema with Embedded Courses:
const studentSchema = new mongoose.Schema({
  name: String,
  courses: [{ title: String, courseId: mongoose.Schema.Types.ObjectId }]
});

Course Schema with Embedded Students:
const courseSchema = new mongoose.Schema({
  title: String,
  students: [{ name: String, studentId: mongoose.Schema.Types.ObjectId }]
});

C. Using References and populate() in Mongoose :
References allow you to create relationships between documents by storing the ObjectId of one document in another. populate() is a Mongoose method that lets you replace the ObjectId references with the actual documents.

C1. Setting Up References:
Define a schema with references:
const postSchema = new mongoose.Schema({
  title: String,
  content: String,
  author: { type: mongoose.Schema.Types.ObjectId, ref: 'User' }
});

C2. Using populate():
Example Query with populate():
Post.findOne({ _id: postId })
  .populate('author')
  .exec((err, post) => {
    if (err) {
      console.error('Error populating author:', err);
    } else {
      console.log('Post with populated author:', post);
    }
  });
populate('author') replaces the author field (which contains an ObjectId) with the actual User document.

* Embedding Documents vs. Referencing Documents :

A. Embedding Documents:
Pros:
Atomic Operations: Related data is stored together, reducing the need for multiple queries.
Simplicity: Easier to model and query when the data is frequently accessed together.
Performance: Better performance for read operations when all related data is needed.

Cons:
Document Size Limits: MongoDB has a document size limit (16MB), which can be a limitation if embedding large arrays or deeply nested documents.
Data Duplication: Updates to embedded data require updating all documents where the data is embedded.

B. Referencing Documents:
Pros:
Flexibility: Allows for more complex relationships and avoids document size limitations.
Normalization: Reduces data duplication, making updates simpler as related data is stored in a single place.

Cons:
Complexity: Requires additional queries (using populate()) to retrieve related data, potentially impacting performance.
Consistency: More complex to ensure data consistency across multiple documents.


9. 